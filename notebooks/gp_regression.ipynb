{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7009facd",
   "metadata": {},
   "source": [
    "# GP regression\n",
    "\n",
    "This notebook compares MESS variants to ESS ($M=1$) on the Gaussian process regression problem from Murray et. al (2010) and summarizes mixing\n",
    "diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cdd251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Get absolute path to src directory (go up from notebooks to repo root)\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "src_path = os.path.join(repo_root, 'src')\n",
    "sys.path.insert(0, src_path)\n",
    "\n",
    "print(f\"Repo root: {repo_root}\")\n",
    "print(f\"Added to path: {src_path}\")\n",
    "print(f\"Does it exist? {os.path.exists(src_path)}\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mess.data.gp_regression import generate_gp_regression_data\n",
    "from mess.problems.gp_regression import GaussianProcessRegression\n",
    "from mess.algorithms.ess import ess_step\n",
    "from mess.algorithms.mess import mess_step\n",
    "from mess.algorithms.effective_sample_size import estimate_effective_sample_size, compute_autocorrelation, integrated_autocorrelation_time, plot_ess_histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a547a5",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set problem and sampler parameters used throughout the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fd3e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem parameters\n",
    "num_data = 200\n",
    "D = 10\n",
    "length_scale = 1.0\n",
    "noise_variance = 0.09\n",
    "\n",
    "# Sampler parameters\n",
    "n_iters = 10000\n",
    "burn_in = 500\n",
    "\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046eac48",
   "metadata": {},
   "source": [
    "## Data generation\n",
    "\n",
    "Simulate GP regression data and initialize the latent function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd18e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_gp_regression_data(\n",
    "    num_data=num_data,\n",
    "    num_dims=D,\n",
    "    length_scale=length_scale,\n",
    "    noise_variance=noise_variance,\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "X = data[\"X\"]\n",
    "y = data[\"y\"]\n",
    "x0 = data[\"f_init\"]\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49241a1a",
   "metadata": {},
   "source": [
    "## Problem setup\n",
    "\n",
    "Build the GP regression log-likelihood used by the samplers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533b3e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = GaussianProcessRegression(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    length_scale=length_scale,\n",
    "    noise_variance=noise_variance,\n",
    ")\n",
    "print(\"Initial log-likelihood:\", problem.log_likelihood(x0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac78c70",
   "metadata": {},
   "source": [
    "## Run samplers\n",
    "\n",
    "Run ESS, MESS, and MESS variants and record wall-clock time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47b1ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_ess = np.random.default_rng(seed)\n",
    "\n",
    "chain_ess = np.zeros((n_iters + 1, num_data))\n",
    "chain_ess[0] = x0.copy()  # Initial state\n",
    "intervals_ess = np.zeros(n_iters, dtype=int)    \n",
    "x = x0.copy()\n",
    "\n",
    "t0 = time.time()\n",
    "for t in range(n_iters):\n",
    "    x, nr_intervals_ess, P1_ess = ess_step(x, problem, rng_ess)\n",
    "    chain_ess[t + 1] = x\n",
    "    intervals_ess[t] = nr_intervals_ess\n",
    "t1 = time.time()\n",
    "ess_time = t1 - t0\n",
    "print(f\"ESS sampling time: {ess_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a639d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_mess = np.random.default_rng(seed)\n",
    "\n",
    "M = 20\n",
    "chain_mess = np.zeros((n_iters + 1, num_data))\n",
    "chain_mess[0] = x0.copy()  # Initial state\n",
    "intervals_mess = np.zeros(n_iters, dtype=int)\n",
    "x = x0.copy()\n",
    "\n",
    "# Uniform transition matrix\n",
    "t0 = time.time()\n",
    "for t in range(n_iters):\n",
    "    x, nr_intervals_mess, P1_mess = mess_step(x, problem, rng_mess, M=M)\n",
    "    chain_mess[t + 1] = x\n",
    "    intervals_mess[t] = nr_intervals_mess\n",
    "t1 = time.time()\n",
    "mess_time = t1 - t0\n",
    "print(f\"MESS sampling time: {mess_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e2086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_mess = np.random.default_rng(seed)\n",
    "\n",
    "chain_mess_ang = np.zeros((n_iters + 1, num_data))\n",
    "chain_mess_ang[0] = x0.copy()  # Initial state\n",
    "intervals_mess_ang = np.zeros(n_iters, dtype=int)\n",
    "x = x0.copy()\n",
    "\n",
    "# Transition matrix with LP, angular distance\n",
    "t0 = time.time()\n",
    "for t in range(n_iters):\n",
    "    x, nr_intervals_mess, P1_mess = mess_step(x, problem, rng_mess, M=M, \n",
    "                                              use_lp=True, distance_metric='angular', \n",
    "                                              lam=0.05)\n",
    "    chain_mess_ang[t + 1] = x\n",
    "    intervals_mess_ang[t] = nr_intervals_mess\n",
    "t1 = time.time()\n",
    "mess_ang_time = t1 - t0\n",
    "print(f\"MESS (angular) sampling time: {mess_ang_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961719e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_mess = np.random.default_rng(seed)\n",
    "M = 20\n",
    "chain_mess_eucl = np.zeros((n_iters + 1, num_data))\n",
    "chain_mess_eucl[0] = x0.copy()  # Initial state\n",
    "intervals_mess_eucl = np.zeros(n_iters, dtype=int)\n",
    "x = x0.copy()\n",
    "\n",
    "# Transition matrix with LP, euclidean distance\n",
    "t0 = time.time()\n",
    "for t in range(n_iters):\n",
    "    x, nr_intervals_mess, P1_mess = mess_step(x, problem, rng_mess, M=M, \n",
    "                                              use_lp=True, distance_metric='euclidean', \n",
    "                                              lam=0.05)\n",
    "    chain_mess_eucl[t + 1] = x\n",
    "    intervals_mess_eucl[t] = nr_intervals_mess\n",
    "t1 = time.time()\n",
    "mess_eucl_time = t1 - t0\n",
    "print(f\"MESS (euclidean) sampling time: {mess_eucl_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11facfb",
   "metadata": {},
   "source": [
    "### Optional\n",
    "To experiment with settings in the LP optimization problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0126e98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_mess = np.random.default_rng(seed)\n",
    "M = 100\n",
    "chain_mess_lam0 = np.zeros((n_iters + 1, num_data))\n",
    "chain_mess_lam0[0] = x0.copy()  # Initial state\n",
    "intervals_mess_lam0 = np.zeros(n_iters, dtype=int)\n",
    "x = x0.copy()\n",
    "\n",
    "# Transition matrix with LP, angular distance, lambda=0\n",
    "every = 5000\n",
    "lam = 0\n",
    "print(f\"Testing MESS (M={M}) with regularization parameter lambda={lam}, \\nprinting transition matrix row every {every} iterations:\\n\")\n",
    "t0 = time.time()\n",
    "for t in range(n_iters):\n",
    "    x, nr_intervals_mess, P1_mess = mess_step(x, problem, rng_mess, M=M, \n",
    "                                              use_lp=True, distance_metric='euclidean', \n",
    "                                              lam=lam)\n",
    "    chain_mess_lam0[t + 1] = x\n",
    "    intervals_mess_lam0[t] = nr_intervals_mess\n",
    "    \n",
    "    # Print transition matrix row every `every` iterations\n",
    "    if (t + 1) % every == 0 and P1_mess is not None:\n",
    "        print(f\"Iteration {t + 1}:\")\n",
    "        print(f\"  Transition matrix row: {P1_mess}\")\n",
    "        print()\n",
    "        \n",
    "t1 = time.time()\n",
    "mess_lam0_time = t1 - t0\n",
    "print(f\"MESS (lambda=0) sampling time: {mess_lam0_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4371a3e8",
   "metadata": {},
   "source": [
    "## Interval diagnostics\n",
    "\n",
    "Compare the number of intervals per iteration across samplers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c313d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(intervals_ess)\n",
    "plt.plot(intervals_mess)\n",
    "plt.plot(intervals_mess_ang)\n",
    "plt.plot(intervals_mess_eucl)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Number of intervals\")\n",
    "plt.legend([\"ESS\", \"MESS\", \"MESS Angular\", \"MESS Euclidean\"])\n",
    "plt.title(\"Number of intervals per iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc71b01a",
   "metadata": {},
   "source": [
    "## Log-likelihood trace\n",
    "\n",
    "Inspect convergence and mixing via the log-likelihood trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b85bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_ess = np.array([problem.log_likelihood(x) for x in chain_ess])\n",
    "ll_mess = np.array([problem.log_likelihood(x) for x in chain_mess])\n",
    "ll_mess_ang = np.array([problem.log_likelihood(x) for x in chain_mess_ang])\n",
    "ll_mess_eucl = np.array([problem.log_likelihood(x) for x in chain_mess_eucl])\n",
    "\n",
    "plt.plot(ll_ess, label=\"ESS\")\n",
    "plt.plot(ll_mess, label=\"MESS\")\n",
    "plt.plot(ll_mess_ang, label=\"MESS Angular\")\n",
    "plt.plot(ll_mess_eucl, label=\"MESS Euclidean\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.legend()\n",
    "plt.title(\"Log-likelihood trace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27bd097",
   "metadata": {},
   "source": [
    "## Trace plots\n",
    "\n",
    "Compare coordinate-level traces across samplers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d130a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [0, 10, 50]\n",
    "\n",
    "fig, axes = plt.subplots(len(idx), 1, figsize=(6, 10))\n",
    "for i, k in enumerate(idx):\n",
    "    axes[i].plot(chain_ess[:, k], alpha=0.7, label=\"ESS\")\n",
    "    axes[i].plot(chain_mess[:, k], alpha=0.7, label=\"MESS\")\n",
    "    axes[i].plot(chain_mess_ang[:, k], alpha=0.7, label=\"MESS Angular\")\n",
    "    axes[i].plot(chain_mess_eucl[:, k], alpha=0.7, label=\"MESS Euclidean\")\n",
    "    axes[i].set_title(f\"Coordinate {k}\")\n",
    "    axes[i].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c036de97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traceplot for all coordinates and algorithms at the same time\n",
    "fig, axes = plt.subplots(1, 4, figsize=(15, 4))\n",
    "\n",
    "algorithms = [\n",
    "    (\"ESS\", chain_ess[:]),\n",
    "    (\"MESS\", chain_mess[:]),\n",
    "    (\"MESS Angular\", chain_mess_ang[:]),\n",
    "    (\"MESS Euclidean\", chain_mess_eucl[:]),\n",
    "]\n",
    "\n",
    "for idx, (algo_name, chain) in enumerate(algorithms):\n",
    "    for k in range(num_data):\n",
    "        axes[idx].plot(chain[:, k], alpha=0.1, linewidth=0.5)\n",
    "    axes[idx].set_title(algo_name)\n",
    "    axes[idx].set_xlabel(\"Iteration\")\n",
    "    axes[idx].set_ylabel(\"Value\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60021ed",
   "metadata": {},
   "source": [
    "## Posterior summary\n",
    "\n",
    "Compute posterior mean and standard deviation, then compare to the true latent function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeed97e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_true = data[\"f_true\"]\n",
    "\n",
    "samples_ess = chain_ess[burn_in + 1:]  # Skip initial state and burn_in\n",
    "samples_mess = chain_mess[burn_in + 1:]\n",
    "samples_mess_ang = chain_mess_ang[burn_in + 1:]\n",
    "samples_mess_eucl = chain_mess_eucl[burn_in + 1:]\n",
    "\n",
    "mean_ess = samples_ess.mean(axis=0)\n",
    "mean_mess = samples_mess.mean(axis=0)\n",
    "mean_mess_ang = samples_mess_ang.mean(axis=0)\n",
    "mean_mess_eucl = samples_mess_eucl.mean(axis=0)\n",
    "\n",
    "std_ess = samples_ess.std(axis=0)\n",
    "std_mess = samples_mess.std(axis=0)\n",
    "std_mess_ang = samples_mess_ang.std(axis=0)\n",
    "std_mess_eucl = samples_mess_eucl.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55141cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(f_true, label=\"True f\", color=\"black\", linewidth=2)\n",
    "plt.plot(mean_ess, label=\"ESS posterior mean\", alpha=0.8)\n",
    "plt.plot(mean_mess, label=\"MESS posterior mean\", alpha=0.8)\n",
    "plt.plot(mean_mess_ang, label=\"MESS Angular posterior mean\", alpha=0.8)\n",
    "plt.plot(mean_mess_eucl, label=\"MESS Euclidean posterior mean\", alpha=0.8)\n",
    "plt.legend()\n",
    "plt.title(\"Posterior mean vs true latent function\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"f\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6db4cc",
   "metadata": {},
   "source": [
    "## Eff. Sample Size diagnostics\n",
    "\n",
    "Compute Eff. Sample Size and Eff. Sample Size per minute for each sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f1371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Eff. Sample Size for each method\n",
    "max_lag = 1000\n",
    "ess_ess = estimate_effective_sample_size(chain_ess[burn_in + 1:, :], max_lag=max_lag)\n",
    "ess_mess = estimate_effective_sample_size(chain_mess[burn_in + 1:, :], max_lag=max_lag)\n",
    "ess_mess_ang = estimate_effective_sample_size(chain_mess_ang[burn_in + 1:, :], max_lag=max_lag)\n",
    "ess_mess_eucl = estimate_effective_sample_size(chain_mess_eucl[burn_in + 1:, :], max_lag=max_lag)\n",
    "\n",
    "# Eff. Sample Size per minute\n",
    "percentage_useful_samples = (n_iters - burn_in) / n_iters\n",
    "ess_minute_ess = ess_ess / (percentage_useful_samples * ess_time / 60.0)\n",
    "ess_minute_mess = ess_mess / (percentage_useful_samples * mess_time / 60.0)\n",
    "ess_minute_mess_ang = ess_mess_ang / (percentage_useful_samples * mess_ang_time / 60.0)\n",
    "ess_minute_mess_eucl = ess_mess_eucl / (percentage_useful_samples * mess_eucl_time / 60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa1e18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eff. Sample Size histograms for all algorithms\n",
    "algorithms = [\n",
    "    (\"ESS (M=1)\", ess_ess, ess_minute_ess),\n",
    "    (\"MESS Uniform\", ess_mess, ess_minute_mess),\n",
    "    (\"MESS Angular\", ess_mess_ang, ess_minute_mess_ang),\n",
    "    (\"MESS Euclidean\", ess_mess_eucl, ess_minute_mess_eucl),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, len(algorithms), figsize=(16, 7), sharey='row', sharex='row')\n",
    "for col, (name, ess_vals, ess_min_vals) in enumerate(algorithms):\n",
    "    ax = axes[0, col]\n",
    "    ax.hist(ess_vals, bins=10, alpha=0.7, color=\"steelblue\")\n",
    "    ax.set_title(name)\n",
    "    if col == 0:\n",
    "        ax.set_ylabel(\"Frequency\")\n",
    "    ax.set_xlabel(\"Eff. Sample Size\")\n",
    "\n",
    "    ax = axes[1, col]\n",
    "    ax.hist(ess_min_vals, bins=10, alpha=0.7, color=\"seagreen\")\n",
    "    if col == 0:\n",
    "        ax.set_ylabel(\"Frequency\")\n",
    "    ax.set_xlabel(\"Eff. Sample Size / min\")\n",
    "\n",
    "plt.suptitle(\"Eff. Sample Size diagnostics\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2c213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table for Eff. Sample Size metrics\n",
    "summary_rows = []\n",
    "for name, ess_vals, ess_min_vals in algorithms:\n",
    "    summary_rows.append([\n",
    "        name,\n",
    "        float(np.mean(ess_vals)),\n",
    "        float(np.mean(ess_min_vals)),\n",
    "    ])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5, 1.6 + 0.4 * len(summary_rows)))\n",
    "ax.axis(\"off\")\n",
    "table = ax.table(\n",
    "    cellText=[[row[0], f\"{row[1]:.2f}\", f\"{row[2]:.2f}\"] for row in summary_rows],\n",
    "    colLabels=[\"Algorithm\", \"Eff. Sample Size (mean)\", \"Eff. Sample Size / min (mean)\"],\n",
    "    loc=\"center\",\n",
    "    cellLoc=\"center\",\n",
    ")\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1, 1.4)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mess-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
